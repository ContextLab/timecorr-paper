{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucyowen/.pyenv/versions/3.7.2/envs/my-data-project/lib/python3.7/site-packages/nilearn/datasets/__init__.py:89: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  \"Numpy arrays.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import supereeg as se\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob as glob\n",
    "import copy\n",
    "from scipy.io import loadmat as load\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_indices(ary, n):\n",
    "    \"\"\"Returns the n largest indices from a numpy array.\"\"\"\n",
    "    flat = ary.flatten()\n",
    "    indices = np.argpartition(flat, -n)[-n:]\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    return np.unravel_index(indices, ary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smallest_indices(ary, n):\n",
    "    \"\"\"Returns the n largest indices from a numpy array.\"\"\"\n",
    "    flat = ary.flatten()\n",
    "    indices = np.argpartition(flat, n)[:n]\n",
    "    indices = indices[np.argsort(flat[indices])]\n",
    "    return np.unravel_index(indices, ary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf(centers, widths, locs):\n",
    "    \"\"\"\n",
    "    Radial basis function\n",
    "    Parameters\n",
    "    ----------\n",
    "    centers : ndarray\n",
    "        rbf coordinates (one row per RBF)\n",
    "    widths : ndarray\n",
    "        RBF radii\n",
    "    locs : ndarray\n",
    "        locations to evaluate the RBFs (one row per location)\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    results : ndarray\n",
    "        Matrix of RBF weights for each RBF (row), at each location (column)\n",
    "    \"\"\"    \n",
    "    weights = np.exp(np.divide(-cdist(locs, centers, metric='euclidean') ** 2, np.tile(np.array(widths, ndmin=2), [locs.shape[0], 1])))\n",
    "    return weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileDir = os.path.dirname(os.path.realpath('__file__'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.path.join(fileDir, '../../data/', 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(results_dir, 'mean_corrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "replication_dir ='../figs/replication/'\n",
    "if not os.path.exists(replication_dir):\n",
    "    os.mkdir(replication_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neurosynth_dir ='../figs/neurosynth_data_/'\n",
    "neurosynth_dir = os.path.join(replication_dir, 'neurosynth_data')\n",
    "if not os.path.exists(neurosynth_dir):\n",
    "    os.mkdir(neurosynth_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_dir = os.path.join(neurosynth_dir, 'bos')\n",
    "if not os.path.exists(bo_dir):\n",
    "    os.mkdir(bo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = load(os.path.join(fileDir, '../../data/pieman_posterior_K700.mat'))\n",
    "centers = posterior['posterior']['centers'][0][0][0][0][0]\n",
    "widths = np.array(list(posterior['posterior']['widths'][0][0][0][0][0][:, 0].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = se.helpers._gray(res=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = np.arange(0,15,1)\n",
    "conditions = ['intact', 'paragraph', 'rest', 'word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot save bo rest_5\n",
      "cannot save bo intact_9\n",
      "cannot save bo intact_11\n",
      "cannot save bo rest_12\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.DataFrame()\n",
    "\n",
    "for l in levels:\n",
    "    for c in conditions:\n",
    "        conds = glob.glob(os.path.join(data_dir, f'level_{l}', f'{c}.npy'))\n",
    "        g_m = np.load(conds[0])\n",
    "\n",
    "        networks = copy.copy(g_m)\n",
    "        np.fill_diagonal(networks, 0)\n",
    "        net_inds = largest_indices(np.triu(np.abs(networks)), top_n)\n",
    "        net_inds = np.concatenate((net_inds[0], net_inds[1]))\n",
    "        temp_locs = centers[net_inds]\n",
    "        temp_widths = widths[net_inds]\n",
    "        \n",
    "        w = rbf(temp_locs, temp_widths, template.get_locs().values)\n",
    "        b = se.Brain(data=np.array(np.sum(w, axis=0), ndmin=2), locs=template.get_locs(), minimum_voxel_size=2)\n",
    "        \n",
    "        data = b.get_data().values.ravel()\n",
    "        xyz = b.get_locs().values\n",
    "        xyz = xyz[data>.999]\n",
    "        data = data[data>.999]\n",
    "        data = np.ones(data.shape)+l\n",
    "        \n",
    "        try:\n",
    "            bo = se.Brain(data=data, locs=xyz)\n",
    "            outfile = c+ '_' + str(l+1)\n",
    "            bo.save(os.path.join(bo_dir, outfile + '_largest_abs'))\n",
    "        except:\n",
    "            print('cannot save bo ' + outfile)\n",
    "\n",
    "        np.save(os.path.join(bo_dir,f'{c}_{l + 1}_data_largest_abs.npy'), data)\n",
    "        np.save(os.path.join(bo_dir,f'{c}_{l + 1}_locs_largest_abs.npy'), xyz)\n",
    "        \n",
    "        part_data = pd.DataFrame()\n",
    "        part_data['X'] = xyz[:, 0]\n",
    "        part_data['Y'] = xyz[:, 1]\n",
    "        part_data['Z'] = xyz[:, 2]\n",
    "        part_data['Data'] = data\n",
    "        part_data['Condition'] = c\n",
    "        part_data['Level'] = l + 1\n",
    "        \n",
    "        if full_data.empty:\n",
    "            full_data = part_data\n",
    "        else:\n",
    "            full_data = full_data.append(part_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.to_excel(os.path.join(data_dir, 'bo_for_plots.xlsx'), sheet_name='bos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "posteriors_data = pd.DataFrame()\n",
    "posteriors_data['Centers_X'] = centers[:, 0]\n",
    "posteriors_data['Centers_Y'] = centers[:, 1]\n",
    "posteriors_data['Centers_Z'] = centers[:, 2]\n",
    "posteriors_data['Widths'] = widths\n",
    "\n",
    "posteriors_data.to_excel(os.path.join(data_dir, 'posteriors.xlsx'), sheet_name='posteriors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
