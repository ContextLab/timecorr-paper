{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timecorr as tc\n",
    "import hypertools as hyp\n",
    "import supereeg as se\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation as ani\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob as glob\n",
    "from scipy.io import loadmat as load\n",
    "import numba\n",
    "import copy\n",
    "import nilearn as nl\n",
    "import nibabel as nib\n",
    "from nilearn import plotting as ni_plt\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from collections import deque\n",
    "from IPython.display import HTML\n",
    "import matlab.engine as mlab\n",
    "import matlab\n",
    "from neurosynth import Dataset\n",
    "from neurosynth import meta, decode, network\n",
    "import supereeg as se\n",
    "\n",
    "\n",
    "from visbrain.objects import BrainObj, ColorbarObj, SceneObj, SourceObj\n",
    "from visbrain.io import download_file, read_stc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_indices(ary, n):\n",
    "    \"\"\"Returns the n largest indices from a numpy array.\"\"\"\n",
    "    flat = ary.flatten()\n",
    "    indices = np.argpartition(flat, -n)[-n:]\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    return np.unravel_index(indices, ary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smallest_indices(ary, n):\n",
    "    \"\"\"Returns the n largest indices from a numpy array.\"\"\"\n",
    "    flat = ary.flatten()\n",
    "    indices = np.argpartition(flat, n)[:n]\n",
    "    indices = indices[np.argsort(flat[indices])]\n",
    "    return np.unravel_index(indices, ary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf(centers, widths, locs):\n",
    "    \"\"\"\n",
    "    Radial basis function\n",
    "    Parameters\n",
    "    ----------\n",
    "    centers : ndarray\n",
    "        rbf coordinates (one row per RBF)\n",
    "    widths : ndarray\n",
    "        RBF radii\n",
    "    locs : ndarray\n",
    "        locations to evaluate the RBFs (one row per location)\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    results : ndarray\n",
    "        Matrix of RBF weights for each RBF (row), at each location (column)\n",
    "    \"\"\"    \n",
    "    weights = np.exp(np.divide(-cdist(locs, centers, metric='euclidean') ** 2, np.tile(np.array(widths, ndmin=2), [locs.shape[0], 1])))\n",
    "    return weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir = '../figs'\n",
    "if not os.path.exists(figdir):\n",
    "    os.mkdir(figdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurosynth_dir ='../figs/neurosynth_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_f_dir = os.path.join(neurosynth_dir, 'figs')\n",
    "if not os.path.exists(n_f_dir):\n",
    "    os.mkdir(n_f_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1aa5c9bd4a0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnii_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurosynth_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'niis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnii_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnii_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "nii_dir = os.path.join(neurosynth_dir, 'niis')\n",
    "if not os.path.exists(nii_dir):\n",
    "    os.mkdir(nii_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_dir = os.path.join(neurosynth_dir, 'txts')\n",
    "if not os.path.exists(txt_dir):\n",
    "    os.mkdir(txt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddir = '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.path.join(os.getenv('HOME'), 'Desktop', 'timecorr_env', 'timecorr_paper', 'pieman', 'results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = load(os.path.join(results_dir, '../data/pieman_posterior_K700.mat'))\n",
    "centers = posterior['posterior']['centers'][0][0][0][0][0]\n",
    "widths = np.array(list(posterior['posterior']['widths'][0][0][0][0][0][:, 0].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(results_dir, 'mean_corrs')\n",
    "corrs_dir = os.path.join(data_dir, 'corrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = np.arange(0,16,1)\n",
    "conditions = ['intact', 'paragraph', 'rest', 'word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = se.helpers._gray(res=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "l = 0\n",
    "c = 'intact'\n",
    "conds = glob.glob(os.path.join(data_dir, f'level_{l}', f'{c}.npy'))\n",
    "g_m = np.load(conds[0])\n",
    "\n",
    "networks = copy.copy(g_m)\n",
    "np.fill_diagonal(networks, 0)\n",
    "net_inds = largest_indices(np.triu(networks), top_n)\n",
    "pos_mask = networks[net_inds] > 0\n",
    "net_inds = np.concatenate((net_inds[0][pos_mask], net_inds[1][pos_mask]))\n",
    "temp_locs = centers[net_inds]\n",
    "temp_widths = widths[net_inds]\n",
    "\n",
    "w = rbf(temp_locs, temp_widths, template.get_locs().values)\n",
    "b = se.Brain(data=np.array(np.sum(w, axis=0), ndmin=2), locs=template.get_locs(), minimum_voxel_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lucyowen/repos/timecorr-paper/code/figs/neurosynth_data/niis\n"
     ]
    }
   ],
   "source": [
    "cd /Users/lucyowen/repos/timecorr-paper/code/figs/neurosynth_data/niis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import supereeg as se\n",
    "import numpy as np\n",
    "from visbrain.objects import BrainObj, ColorbarObj, SceneObj, SourceObj\n",
    "from visbrain.io import download_file, read_stc\n",
    "\n",
    "\n",
    "b = se.load('/Users/lucyowen/repos/timecorr-paper/code/figs/neurosynth_data/niis/intact_1_largest.bo')\n",
    "data = b.get_data().values.ravel()\n",
    "xyz = b.get_locs().values\n",
    "xyz = xyz[data>.9999]\n",
    "data = data[data>.9999]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1572,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'se' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b52d9638d173>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbo_try\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxyz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbo_try\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'se' is not defined"
     ]
    }
   ],
   "source": [
    "bo_try = se.Brain(data=data, locs=xyz)\n",
    "bo_try.plot_locs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try visbrain for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "\n",
    "for l in [0,1,2,3,14]:\n",
    "    for c in conditions:\n",
    "        conds = glob.glob(os.path.join(data_dir, f'level_{l}', f'{c}.npy'))\n",
    "        g_m = np.load(conds[0])\n",
    "\n",
    "        networks = copy.copy(g_m)\n",
    "        np.fill_diagonal(networks, 0)\n",
    "        net_inds = largest_indices(np.triu(networks), top_n)\n",
    "        pos_mask = networks[net_inds] > 0\n",
    "        net_inds = np.concatenate((net_inds[0][pos_mask], net_inds[1][pos_mask]))\n",
    "        temp_locs = centers[net_inds]\n",
    "        temp_widths = widths[net_inds]\n",
    "        \n",
    "        w = rbf(temp_locs, temp_widths, template.get_locs().values)\n",
    "        b = se.Brain(data=np.array(np.sum(w, axis=0), ndmin=2), locs=template.get_locs(), minimum_voxel_size=2)\n",
    "        nii = se.Nifti(b)\n",
    "        outfile = c+ '_' + str(l+1)\n",
    "        nii.save(os.path.join(nii_dir, outfile + '_largest'))\n",
    "        ni_plt.plot_glass_brain(nii, display_mode='lyrz', output_file=os.path.join(n_f_dir, outfile + '_largest.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "\n",
    "for l in [0,1,2,3,14]:\n",
    "    for c in conditions:\n",
    "        conds = glob.glob(os.path.join(data_dir, f'level_{l}', f'{c}.npy'))\n",
    "        g_m = np.load(conds[0])\n",
    "\n",
    "        networks = copy.copy(g_m)\n",
    "        np.fill_diagonal(networks, 0)\n",
    "        net_inds = smallest_indices(np.triu(networks), top_n)\n",
    "        neg_mask = networks[net_inds] < 0\n",
    "        net_inds = np.concatenate((net_inds[0][neg_mask], net_inds[1][neg_mask]))\n",
    "        temp_locs = centers[net_inds]\n",
    "        temp_widths = widths[net_inds]\n",
    "        \n",
    "        w = rbf(temp_locs, temp_widths, template.get_locs().values)\n",
    "        b = se.Brain(data=np.array(np.sum(w, axis=0), ndmin=2), locs=template.get_locs(), minimum_voxel_size=2)\n",
    "        nii = se.Nifti(b)\n",
    "        outfile = c+ '_' + str(l+1)\n",
    "        nii.save(os.path.join(nii_dir, outfile + '_smallest'))\n",
    "        ni_plt.plot_glass_brain(nii, display_mode='lyrz', output_file=os.path.join(n_f_dir, outfile + '_smallest.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 10\n",
    "\n",
    "for l in [0,1,2,3,14]:\n",
    "    for c in conditions:\n",
    "        conds = glob.glob(os.path.join(data_dir, f'level_{l}', f'{c}.npy'))\n",
    "        g_m = np.load(conds[0])\n",
    "\n",
    "        networks = copy.copy(g_m)\n",
    "        np.fill_diagonal(networks, 0)\n",
    "        net_inds = largest_indices(np.triu(np.abs(networks)), top_n)\n",
    "        net_inds = np.concatenate((net_inds[0], net_inds[1]))\n",
    "        temp_locs = centers[net_inds]\n",
    "        temp_widths = widths[net_inds]\n",
    "        \n",
    "        w = rbf(temp_locs, temp_widths, template.get_locs().values)\n",
    "        b = se.Brain(data=np.array(np.sum(w, axis=0), ndmin=2), locs=template.get_locs(), minimum_voxel_size=2)\n",
    "        nii = se.Nifti(b)\n",
    "        outfile = c+ '_' + str(l+1)\n",
    "        nii.save(os.path.join(nii_dir, outfile + '_largest_abs'))\n",
    "        ni_plt.plot_glass_brain(nii, display_mode='lyrz', output_file=os.path.join(n_f_dir, outfile + '_largest_abs.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load(os.path.join(neurosynth_dir, 'dataset.pkl'))\n",
    "decoder = decode.Decoder(dataset=dataset, threshold=0.1, features=['taste', 'disgust', 'emotion', 'auditory', 'pain', 'somatosensory', 'conflict', 'switching', 'inhibition'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neurosynth as ns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timecorr as tc\n",
    "import hypertools as hyp\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation as ani\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob as glob\n",
    "from scipy.io import loadmat as load\n",
    "import numba\n",
    "import copy\n",
    "from scipy.spatial.distance import pdist, cdist, squareform\n",
    "from collections import deque\n",
    "from neurosynth import Dataset\n",
    "from neurosynth import meta, decode, network\n",
    "# import mkl\n",
    "# mkl.set_num_threads(4)\n",
    "\n",
    "#neurosynth_dir ='/dartfs/rc/lab/D/DBIC/CDL/f002s72/timecorr_paper/pieman/results/neurosynth_data'\n",
    "nii_dir = os.path.join(neurosynth_dir, 'niis')\n",
    "txt_dir = os.path.join(neurosynth_dir, 'txts')\n",
    "\n",
    "# ns.dataset.download(path='neurosynth_dir', unpack=True)\n",
    "# dataset = Dataset(os.path.join(neurosynth_dir,'database.txt'))\n",
    "# dataset.add_features(os.path.join(neurosynth_dir, 'features.txt'))\n",
    "# dataset.save(os.path.join(neurosynth_dir,'dataset.pkl'))\n",
    "\n",
    "# dataset = Dataset.load(os.path.join(neurosynth_dir, 'dataset.pkl'))\n",
    "# decoder = decode.Decoder(dataset=dataset, threshold=0.1, features=None)\n",
    "\n",
    "conditions = ['intact', 'paragraph', 'rest', 'word']\n",
    "\n",
    "for l in [1,2,3,4,15]:\n",
    "    for c in conditions:\n",
    "        in_file = c+ '_' + str(l)\n",
    "        data = decoder.decode([os.path.join(nii_dir, in_file + '_smallest.nii')], save=None)\n",
    "        renamed = data.reset_index()\n",
    "        renamed.columns = ['feature', 'value']\n",
    "        s_rename = renamed.sort_values(by=['value'], ascending=False)\n",
    "        s_rename.to_csv(os.path.join(txt_dir, in_file +'_smallest.txt'))\n",
    "        \n",
    "\n",
    "for l in [1,2,3,4,15]:\n",
    "    for c in conditions:\n",
    "        in_file = c+ '_' + str(l)\n",
    "        data = decoder.decode([os.path.join(nii_dir, in_file + '_largest.nii')], save=None)\n",
    "        renamed = data.reset_index()\n",
    "        renamed.columns = ['feature', 'value']\n",
    "        s_rename = renamed.sort_values(by=['value'], ascending=False)\n",
    "        s_rename.to_csv(os.path.join(txt_dir, in_file +'_largest.txt'))\n",
    "        \n",
    "for l in [1,2,3,4,15]:\n",
    "    for c in conditions:\n",
    "        in_file = c+ '_' + str(l)\n",
    "        data = decoder.decode([os.path.join(nii_dir, in_file + '_largest_abs.nii')], save=None)\n",
    "        renamed = data.reset_index()\n",
    "        renamed.columns = ['feature', 'value']\n",
    "        s_rename = renamed.sort_values(by=['value'], ascending=False)\n",
    "        s_rename.to_csv(os.path.join(txt_dir, in_file +'_largest_abs.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['intact', 'paragraph', 'rest', 'word']\n",
    "full_pd = pd.DataFrame()\n",
    "for l in [1,2,3,4]:\n",
    "    for c in conditions:\n",
    "        in_file = c+ '_' + str(l)\n",
    "        temp_file = pd.read_csv(os.path.join(txt_dir, in_file +'_smallest.txt'))\n",
    "        temp_file['condition'] = c\n",
    "        temp_file['order'] = l\n",
    "        if full_pd.empty:\n",
    "                full_pd = temp_file[:10]\n",
    "        else:\n",
    "            full_pd = full_pd.append(temp_file[:10])\n",
    "\n",
    "pretty_pd = full_pd[['order','condition', 'value', 'feature']]\n",
    "pretty_pd.to_csv(os.path.join(txt_dir,'neg_10_features.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['intact', 'paragraph', 'rest', 'word']\n",
    "full_pd = pd.DataFrame()\n",
    "for l in [1,2,3,4]:\n",
    "    for c in conditions:\n",
    "        in_file = c+ '_' + str(l)\n",
    "        temp_file = pd.read_csv(os.path.join(txt_dir, in_file +'_largest_abs.txt'))\n",
    "        temp_file['condition'] = c\n",
    "        temp_file['order'] = l\n",
    "        if full_pd.empty:\n",
    "                full_pd = temp_file[:10]\n",
    "        else:\n",
    "            full_pd = full_pd.append(temp_file[:10])\n",
    "\n",
    "pretty_pd = full_pd[['order','condition', 'value', 'feature']]\n",
    "pretty_pd.to_csv(os.path.join(txt_dir,'abs_10_features.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "conditions = ['intact', 'paragraph', 'rest', 'word']\n",
    "full_pd = pd.DataFrame()\n",
    "for l in [1,2,3,4]:\n",
    "    for c in conditions:\n",
    "        in_file = c+ '_' + str(l)\n",
    "        temp_file = pd.read_csv(os.path.join(txt_dir, in_file +'_largest.txt'))\n",
    "        temp_file['condition'] = c\n",
    "        temp_file['order'] = l\n",
    "\n",
    "        if full_pd.empty:\n",
    "                full_pd = temp_file[:10]\n",
    "        else:\n",
    "            full_pd = full_pd.append(temp_file[:10])\n",
    "\n",
    "pretty_pd = full_pd[['order','condition', 'value', 'feature']]\n",
    "pretty_pd.to_csv(os.path.join(txt_dir,'pos_10_features.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_pd = full_pd[['order','condition', 'value', 'feature']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_pd.to_csv(os.path.join(txt_dir,'negative_10_features.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = se.helpers._gray(res=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "template.save(os.path.join(nii_dir, 'template.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>condition</th>\n",
       "      <th>value</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>intact</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>intact</td>\n",
       "      <td>0.3020</td>\n",
       "      <td>sounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>intact</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>voice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>intact</td>\n",
       "      <td>0.2676</td>\n",
       "      <td>auditory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>intact</td>\n",
       "      <td>0.2639</td>\n",
       "      <td>sts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>intact</td>\n",
       "      <td>0.2553</td>\n",
       "      <td>superior temporal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>intact</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>spoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>intact</td>\n",
       "      <td>0.2253</td>\n",
       "      <td>stg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>intact</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>speaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>intact</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>temporal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.1756</td>\n",
       "      <td>mpfc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.1612</td>\n",
       "      <td>tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.1519</td>\n",
       "      <td>mind tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.1382</td>\n",
       "      <td>network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>dmn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.1332</td>\n",
       "      <td>social</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>medial prefrontal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>default network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>mental states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>beliefs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.1006</td>\n",
       "      <td>retrieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>relational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>hippocampus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>memory retrieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>dot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>hippocampal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>amygdala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>autobiographical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>mtl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>episodic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>events</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>precuneus posterior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.0970</td>\n",
       "      <td>retrieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>autobiographical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.0929</td>\n",
       "      <td>navigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>thalamic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.0856</td>\n",
       "      <td>memory retrieval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>paragraph</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>hippocampal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.1271</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.1104</td>\n",
       "      <td>words</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.1084</td>\n",
       "      <td>orthographic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>word form</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>visual word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>semantic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0907</td>\n",
       "      <td>ffa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>rest</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>fusiform face</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>amygdala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>0.1154</td>\n",
       "      <td>hippocampus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>0.1032</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>0.0987</td>\n",
       "      <td>parahippocampal cortex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>extinction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>hypothalamus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>mtl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>0.0934</td>\n",
       "      <td>aversive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>hippocampal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>word</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>intense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    order  condition   value                 feature\n",
       "0       1     intact  0.3140                  speech\n",
       "1       1     intact  0.3020                  sounds\n",
       "2       1     intact  0.2983                   voice\n",
       "3       1     intact  0.2676                auditory\n",
       "4       1     intact  0.2639                     sts\n",
       "5       1     intact  0.2553       superior temporal\n",
       "6       1     intact  0.2380                  spoken\n",
       "7       1     intact  0.2253                     stg\n",
       "8       1     intact  0.2207                 speaker\n",
       "9       1     intact  0.2178                temporal\n",
       "0       1  paragraph  0.1756                    mpfc\n",
       "1       1  paragraph  0.1612                     tom\n",
       "2       1  paragraph  0.1519                mind tom\n",
       "3       1  paragraph  0.1382                 network\n",
       "4       1  paragraph  0.1376                     dmn\n",
       "5       1  paragraph  0.1332                  social\n",
       "6       1  paragraph  0.1305       medial prefrontal\n",
       "7       1  paragraph  0.1274         default network\n",
       "8       1  paragraph  0.1252           mental states\n",
       "9       1  paragraph  0.1243                 beliefs\n",
       "0       1       rest  0.1021                  memory\n",
       "1       1       rest  0.1006               retrieval\n",
       "2       1       rest  0.0863              relational\n",
       "3       1       rest  0.0835             hippocampus\n",
       "4       1       rest  0.0828        memory retrieval\n",
       "5       1       rest  0.0822                     dot\n",
       "6       1       rest  0.0818             hippocampal\n",
       "7       1       rest  0.0813                amygdala\n",
       "8       1       rest  0.0794        autobiographical\n",
       "9       1       rest  0.0789                     mtl\n",
       "..    ...        ...     ...                     ...\n",
       "0       4  paragraph  0.1086                  memory\n",
       "1       4  paragraph  0.1063                episodic\n",
       "2       4  paragraph  0.1055                  events\n",
       "3       4  paragraph  0.0974     precuneus posterior\n",
       "4       4  paragraph  0.0970               retrieval\n",
       "5       4  paragraph  0.0946        autobiographical\n",
       "6       4  paragraph  0.0929              navigation\n",
       "7       4  paragraph  0.0920                thalamic\n",
       "8       4  paragraph  0.0856        memory retrieval\n",
       "9       4  paragraph  0.0853             hippocampal\n",
       "0       4       rest  0.1271                    word\n",
       "1       4       rest  0.1104                   words\n",
       "2       4       rest  0.1084            orthographic\n",
       "3       4       rest  0.0993               word form\n",
       "4       4       rest  0.0961             visual word\n",
       "5       4       rest  0.0948                  letter\n",
       "6       4       rest  0.0917                semantic\n",
       "7       4       rest  0.0907                     ffa\n",
       "8       4       rest  0.0874                 reading\n",
       "9       4       rest  0.0850           fusiform face\n",
       "0       4       word  0.1321                amygdala\n",
       "1       4       word  0.1154             hippocampus\n",
       "2       4       word  0.1032                 neutral\n",
       "3       4       word  0.0987  parahippocampal cortex\n",
       "4       4       word  0.0961              extinction\n",
       "5       4       word  0.0956            hypothalamus\n",
       "6       4       word  0.0950                     mtl\n",
       "7       4       word  0.0934                aversive\n",
       "8       4       word  0.0925             hippocampal\n",
       "9       4       word  0.0903                 intense\n",
       "\n",
       "[160 rows x 4 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume = cortex.Volume(voxel_data, 'S1', 'fullhead', mask='template.nii', cmap='RdBu')\n",
    "try_std = standardize_brainspace(template.nii)\n",
    "voxel_data = np.load('try_3.npy')\n",
    "cortex.align.automatic('S1', ' /Users/lucyowen/repos/timecorr-paper/code/figs/neurosynth_data/niis/example-transform', 'intact_1_largest.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### DO THIS ON THE CLUSTER for coactivateion maps\n",
    "### only do this once\n",
    "# import neurosynth as ns\n",
    "# ns.dataset.download(path='neurosynth_dir', unpack=True)\n",
    "# dataset = Dataset(os.path.join(neurosynth_dir,'database.txt'))\n",
    "# dataset.add_features(os.path.join(neurosynth_dir, 'features.txt'))\n",
    "# dataset.save(os.path.join(neurosynth_dir,'dataset.pkl'))\n",
    "\n",
    "# dataset = Dataset.load(os.path.join(neurosynth_dir, 'dataset.pkl'))\n",
    "# decoder = decode.Decoder(dataset=dataset, threshold=0.1, features=['taste', 'disgust', 'emotion', 'auditory', 'pain', 'somatosensory', 'conflict', 'switching', 'inhibition'])\n",
    "\n",
    "# for e, label in enumerate(cond_labels):\n",
    "#     order = label[0]\n",
    "#     con = label[1]\n",
    "#     top_10 = top_coors[:, :, e]\n",
    "\n",
    "#     network.coactivation(dataset, top_10.tolist(), threshold=0.1, r=10, output_dir=neurosynth_dir, prefix=con+ '_' + str(order))\n",
    "    \n",
    "# for e, label in enumerate(cond_labels):\n",
    "#     list_files = glob.glob(os.path.join(neurosynth_dir, con+ '_' + str(order + '*')))\n",
    "#     decoder = decode.Decoder(dataset=dataset, threshold=0.1, features=['taste', 'disgust', 'emotion', 'auditory', 'pain', 'somatosensory', 'conflict', 'switching', 'inhibition'])  # can also pass other useful args\n",
    "#     results_df = decoder.decode(images=list_files, save=None)  # can also pass names specific for the images\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
