{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster code to calculate mean and sliced correlation - up to 15th order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import timecorr as tc\n",
    "import math\n",
    "import scipy.spatial.distance as sd\n",
    "from timecorr.helpers import isfc, autofc, mean_combine, corrmean_combine, vec2mat, reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/dartfs/rc/lab/D/DBIC/CDL/f002s72/timecorr_paper/pieman/results'\n",
    "corrs_dir = os.path.join(data_dir, 'laplace_50_orderedup_corrs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For sliced correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = np.arange(0,16,1)\n",
    "conditions = ['intact', 'paragraph', 'word', 'rest']\n",
    "\n",
    "n = .1\n",
    "percentages = np.arange(n, 1 + n, n)\n",
    "for l in levels:\n",
    "    for c in conditions:\n",
    "        con = os.path.join(corrs_dir, f'lev_{l}'+ f'_{c}' + '.npy')\n",
    "        print(con)\n",
    "        try:\n",
    "            corrs = np.load(con)\n",
    "            mat_corrs = tc.helpers.vec2mat(corrs)\n",
    "            sliced_corrs = np.array([])\n",
    "            next_corrdir = os.path.join(data_dir, 'sliced_corrs', f'level_{l}')\n",
    "            if not os.path.exists(next_corrdir):\n",
    "                os.makedirs(next_corrdir)\n",
    "            for p in percentages:\n",
    "                s = int(p*np.shape(mat_corrs)[-1])\n",
    "                slice_corr = mat_corrs[:, :, s-1]\n",
    "                if sliced_corrs.shape[0] == 0:\n",
    "                    sliced_corrs = slice_corr\n",
    "                else:\n",
    "                    sliced_corrs = np.dstack((sliced_corrs, slice_corr))\n",
    "            np.save(os.path.join(next_corrdir, f'{c}.npy'), sliced_corrs)\n",
    "        except:\n",
    "            print('issue loading: ' + con)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For averaged correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = np.arange(0,16,1)\n",
    "conditions = ['intact', 'paragraph', 'rest', 'word']\n",
    "\n",
    "for l in levels:\n",
    "    for c in conditions:\n",
    "        con = os.path.join(corrs_dir, f'lev_{l}'+ f'_{c}'+ '.npy')\n",
    "        try:\n",
    "            corrs = np.load(con)\n",
    "            mat_corrs = tc.helpers.vec2mat(corrs)\n",
    "            next_corrdir = os.path.join(data_dir, 'mean_corrs', f'level_{l}')\n",
    "            if not os.path.exists(next_corrdir):\n",
    "                os.makedirs(next_corrdir)\n",
    "            mean_corrs = mat_corrs.mean(axis=2)\n",
    "            np.save(os.path.join(next_corrdir, f'{c}.npy'), mean_corrs)\n",
    "        except:\n",
    "            print('issue loading: ' + con)\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
