{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 3)\n",
      "0_data loaded\n",
      "0_reduced data loaded\n",
      "lev_data: [0.14302537 0.00982672 0.08145851 0.05860905 0.07720654 0.13107708\n",
      " 0.08700501 0.12014306 0.02272707 0.12851244 0.09639177 0.13539257\n",
      " 0.01057133 0.13790108 0.10585685 0.1308951  0.00367713 0.12067527\n",
      " 0.09668716 0.12913936 0.128724   0.07483774 0.0746319  0.02725164\n",
      " 0.08344455 0.12127144 0.08733651 0.14921866 0.02892407 0.12531941\n",
      " 0.00920434 0.10757915 0.00811552 0.03756734 0.11342522 0.07662683\n",
      " 0.13405174 0.05758245 0.02685659 0.12033433 0.06650679 0.05281363\n",
      " 0.1424802  0.10382324 0.0140855  0.04675881 0.09704961 0.1055391\n",
      " 0.05488077 0.13526464 0.02879268 0.00695268 0.08356988 0.02071912\n",
      " 0.03402362 0.13897895 0.1128056  0.11573054 0.06335576 0.07580266\n",
      " 0.13779102 0.1006125  0.13705344 0.12579201 0.04377354 0.11815308\n",
      " 0.10788544 0.13513238 0.12071263 0.11163909 0.12464418 0.13629674\n",
      " 0.09941703 0.13384385 0.07131796 0.12588853 0.12783232 0.0322023\n",
      " 0.06038959 0.11707526 0.08449785 0.11743815 0.12465436 0.12224591\n",
      " 0.12178867 0.09948445 0.09592106 0.1103323  0.10675676 0.07654605\n",
      " 0.08514327 0.11017971 0.10761328 0.11099025 0.11285975 0.10948922\n",
      " 0.11189975 0.1120059  0.06901239 0.11248397]\n",
      "data: [0.62200417 0.69342885 0.67412044 ... 0.52664712 0.53187254 0.57161806]\n",
      "1_smooth data calculated\n",
      "1_corrs calculated\n",
      "1_raw data calculated\n",
      "1_reduced data calculated\n",
      "data_r: [0.12777451 0.1436159  0.03540621 0.1045368  0.04934461 0.1115092\n",
      " 0.00712419 0.0835019  0.13715273 0.1065477  0.01513962 0.09677639\n",
      " 0.13165288 0.14203186 0.02727454 0.10657171 0.18040787 0.0639392\n",
      " 0.03992806 0.12860056 0.08598305 0.07612723 0.08606539 0.08853803\n",
      " 0.00647792 0.03968858 0.06676713 0.15981372 0.15829898 0.08838291\n",
      " 0.14795039 0.08180039 0.12761557 0.16327265 0.15019806 0.01082229\n",
      " 0.12794568 0.03236898 0.03312731 0.04779427 0.05590461 0.11481375\n",
      " 0.15280815 0.09503416 0.07490204 0.07746254 0.11509251 0.06059048\n",
      " 0.13201694 0.04121913 0.05514568 0.11546901 0.04439949 0.01198464\n",
      " 0.12427324 0.12027755 0.02418786 0.10972503 0.02930536 0.12291695\n",
      " 0.11948066 0.01102353 0.13395125 0.13975706 0.00448198 0.04359289\n",
      " 0.01994558 0.15000194 0.08701182 0.07194556 0.06505584 0.14996284\n",
      " 0.0540923  0.16832065 0.07227522 0.12853358 0.17261915 0.13517143\n",
      " 0.03915584 0.07174149 0.09793906 0.10588457 0.10792801 0.09706269\n",
      " 0.10372851 0.07311242 0.08265917 0.07949094 0.07778568 0.03916498\n",
      " 0.03918448 0.07279833 0.04849644 0.11997931 0.11350704 0.11372776\n",
      " 0.13516388 0.10263329 0.09982047 0.11310489]\n",
      "lev_data: [0.12777451 0.1436159  0.03540621 0.1045368  0.04934461 0.1115092\n",
      " 0.00712419 0.0835019  0.13715273 0.1065477  0.01513962 0.09677639\n",
      " 0.13165288 0.14203186 0.02727454 0.10657171 0.18040787 0.0639392\n",
      " 0.03992806 0.12860056 0.08598305 0.07612723 0.08606539 0.08853803\n",
      " 0.00647792 0.03968858 0.06676713 0.15981372 0.15829898 0.08838291\n",
      " 0.14795039 0.08180039 0.12761557 0.16327265 0.15019806 0.01082229\n",
      " 0.12794568 0.03236898 0.03312731 0.04779427 0.05590461 0.11481375\n",
      " 0.15280815 0.09503416 0.07490204 0.07746254 0.11509251 0.06059048\n",
      " 0.13201694 0.04121913 0.05514568 0.11546901 0.04439949 0.01198464\n",
      " 0.12427324 0.12027755 0.02418786 0.10972503 0.02930536 0.12291695\n",
      " 0.11948066 0.01102353 0.13395125 0.13975706 0.00448198 0.04359289\n",
      " 0.01994558 0.15000194 0.08701182 0.07194556 0.06505584 0.14996284\n",
      " 0.0540923  0.16832065 0.07227522 0.12853358 0.17261915 0.13517143\n",
      " 0.03915584 0.07174149 0.09793906 0.10588457 0.10792801 0.09706269\n",
      " 0.10372851 0.07311242 0.08265917 0.07949094 0.07778568 0.03916498\n",
      " 0.03918448 0.07279833 0.04849644 0.11997931 0.11350704 0.11372776\n",
      " 0.13516388 0.10263329 0.09982047 0.11310489]\n",
      "data: [0.67397836 0.73286064 0.73245235 ... 0.59628653 0.64426353 0.5868118 ]\n",
      "2_smooth data calculated\n",
      "2_corrs calculated\n",
      "2_raw data calculated\n",
      "2_reduced data calculated\n",
      "data_r: [0.11673606 0.12467842 0.10592967 0.09152751 0.07525425 0.09444332\n",
      " 0.11346492 0.02522004 0.13673002 0.10488391 0.10014631 0.09172004\n",
      " 0.094433   0.1448585  0.1049608  0.09677053 0.15573613 0.00863871\n",
      " 0.08445421 0.13595562 0.05528651 0.0328017  0.07307202 0.03048183\n",
      " 0.07925093 0.03742451 0.03248871 0.15521049 0.14432928 0.01620245\n",
      " 0.11201054 0.00628171 0.07933924 0.15870555 0.159953   0.12994089\n",
      " 0.05949171 0.0093096  0.09770757 0.12192155 0.02050832 0.1394284\n",
      " 0.15184725 0.08694812 0.07882932 0.07953889 0.12230636 0.10077552\n",
      " 0.13930028 0.13611066 0.12027196 0.03148404 0.10335925 0.10675253\n",
      " 0.01631729 0.00716237 0.10651694 0.02776696 0.1436251  0.1309802\n",
      " 0.01499296 0.15233458 0.09767196 0.12663231 0.1408224  0.14362938\n",
      " 0.14701552 0.1194564  0.07778671 0.10784148 0.12805954 0.11789537\n",
      " 0.10163141 0.14123189 0.01932326 0.07916642 0.14808455 0.09046641\n",
      " 0.11324478 0.10453031 0.02862762 0.00624307 0.01180892 0.03920942\n",
      " 0.00973934 0.09035293 0.0678416  0.09708598 0.09696435 0.14141274\n",
      " 0.13593582 0.09812196 0.13601046 0.06071657 0.02817318 0.03333612\n",
      " 0.09951089 0.00557695 0.02141214 0.03370614]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import timecorr as tc\n",
    "import math\n",
    "import scipy.spatial.distance as sd\n",
    "from timecorr.helpers import isfc, autofc, mean_combine, corrmean_combine, vec2mat, reduce\n",
    "import mkl\n",
    "mkl.set_num_threads(4)\n",
    "\n",
    "factors = 700\n",
    "if factors == 100:\n",
    "    pieman_name = '../../data/pieman_ica100.mat'\n",
    "else:\n",
    "    pieman_name = '../../data/pieman_data.mat'\n",
    "\n",
    "\n",
    "\n",
    "pieman_data = loadmat(pieman_name)  \n",
    "\n",
    "pieman_conds = ['word']\n",
    "\n",
    "data = []\n",
    "conds = []\n",
    "\n",
    "\n",
    "for c in pieman_conds:\n",
    "    if c == 'paragraph':\n",
    "        if factors == 700:\n",
    "            next_data = list(map(lambda i: pieman_data[c][:, i][0], np.where(np.arange(pieman_data[c].shape[1]) != 3)[0]))\n",
    "        else:\n",
    "            next_data = list(map(lambda i: pieman_data[c][:, i][0], np.where(np.arange(pieman_data[c].shape[1]) != 0)[0]))\n",
    "    else:\n",
    "        next_data = list(map(lambda i: pieman_data[c][:, i][0], np.arange(pieman_data[c].shape[1])))\n",
    "    data.extend(next_data)\n",
    "    conds.extend([c]*len(next_data))\n",
    "\n",
    "\n",
    "all_data = np.array(data)\n",
    "conds = np.array(conds)\n",
    "cfun = isfc\n",
    "rfun = 'eigenvector_centrality'\n",
    "width = 50\n",
    "smooth = 'laplace'\n",
    "raw = 'delta'\n",
    "\n",
    "results_dir = '/dartfs/rc/lab/D/DBIC/CDL/f002s72/timecorr_paper/pieman/results/'\n",
    "\n",
    "#results_dir = '/Users/lucyowen/Desktop/timecorr_env/timecorr_paper/pieman/results/'\n",
    "\n",
    "corrsdir = os.path.join(results_dir, smooth + '_' + str(50) + '_orderedup_corrs')\n",
    "if not os.path.exists(corrsdir):\n",
    "    os.makedirs(corrsdir)\n",
    "    \n",
    "\n",
    "laplace = {'name': 'Laplace', 'weights': tc.laplace_weights, 'params': {'scale': width}}\n",
    "delta = {'name': '$\\delta$', 'weights': tc.eye_weights, 'params': tc.eye_params}\n",
    "gaussian = {'name': 'Gaussian', 'weights': tc.gaussian_weights, 'params': {'var': width}}\n",
    "mexican_hat = {'name': 'Mexican hat', 'weights': tc.mexican_hat_weights, 'params': {'sigma': width}}\n",
    "\n",
    "smooth_parameter = eval(smooth)\n",
    "raw_parameter = eval(raw)\n",
    "\n",
    "smooth_fun=smooth_parameter['weights']\n",
    "smooth_params=smooth_parameter['params']\n",
    "raw_fun=raw_parameter['weights']\n",
    "raw_params=raw_parameter['params']\n",
    "\n",
    "combine = corrmean_combine  \n",
    "\n",
    "levels = range(16)\n",
    "\n",
    "for c in pieman_conds:\n",
    "    for lev in levels:\n",
    "        if os.path.exists(os.path.join(corrsdir, 'd_'+ str(lev) +'_'+ c +'.npy')):\n",
    "            data = np.load(os.path.join(corrsdir, 'd_'+ str(lev) +'_'+ c +'.npy'))\n",
    "            print(str(lev) + '_data loaded')\n",
    "        else:\n",
    "            if lev == 0:\n",
    "                lev_data = all_data[conds == c]\n",
    "            else:\n",
    "                lev_data = data_r\n",
    "            print('lev_data: ' + str(lev_data[0][0]))\n",
    "            data = np.asarray(tc.timecorr([x for x in lev_data], cfun=isfc, rfun=None,\n",
    "                                          weights_function=smooth_fun, weights_params=smooth_params))\n",
    "            print('data: ' + str(data[0][0]))\n",
    "            print(str(lev) + '_smooth data calculated')\n",
    "            corr = tc.helpers.z2r(np.mean(tc.helpers.r2z(np.stack(data, axis=2)), axis=2))\n",
    "            print(str(lev) + '_corrs calculated')\n",
    "            np.save(os.path.join(corrsdir, 'lev_'+ str(lev) +'_'+ c +'.npy'), corr)\n",
    "            data = np.asarray(tc.timecorr([x for x in lev_data], cfun=isfc, rfun=None,\n",
    "                                          weights_function=raw_fun, weights_params=raw_params))\n",
    "            print(str(lev) + '_raw data calculated')\n",
    "            np.save(os.path.join(corrsdir, 'd_'+ str(lev) +'_'+ c +'.npy'), data)\n",
    "        if os.path.exists(os.path.join(corrsdir, 'd_'+ str(lev) +'_r_'+ c +'.npy')):\n",
    "            data_r = np.load(os.path.join(corrsdir, 'd_'+ str(lev) +'_r_'+ c +'.npy'))\n",
    "            print(str(lev) + '_reduced data loaded')\n",
    "        else:\n",
    "            data_r = np.asarray(reduce([x for x in data], rfun=rfun))\n",
    "            print(str(lev) + '_reduced data calculated')\n",
    "            np.save(os.path.join(corrsdir, 'd_'+ str(lev) +'_r_'+ c +'.npy'), data_r)\n",
    "            print('data_r: ' + str(data_r[0][0]))\n",
    "        del data\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster code to calculate correlations for each order - up to 4th order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import timecorr as tc\n",
    "import math\n",
    "import scipy.spatial.distance as sd\n",
    "from timecorr.helpers import isfc, autofc, mean_combine, corrmean_combine, vec2mat, reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/dartfs/rc/lab/D/DBIC/CDL/f002s72/timecorr_paper/pieman/results'\n",
    "corrs_dir = os.path.join(data_dir, 'laplace_50_orderedup_corrs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For sliced correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#levels = np.arange(0,16,1)\n",
    "levels = [12, 13, 14, 15]\n",
    "#conditions = ['intact', 'paragraph', 'word', 'rest']\n",
    "conditions = ['word']\n",
    "n = .1\n",
    "percentages = np.arange(n, 1 + n, n)\n",
    "for l in levels:\n",
    "    for c in conditions:\n",
    "        con = os.path.join(corrs_dir, f'lev_{l}'+ f'_{c}' + '.npy')\n",
    "        print(con)\n",
    "        try:\n",
    "            corrs = np.load(con)\n",
    "            mat_corrs = tc.helpers.vec2mat(corrs)\n",
    "            sliced_corrs = np.array([])\n",
    "            next_corrdir = os.path.join(data_dir, 'sliced_corrs', f'level_{l}')\n",
    "            if not os.path.exists(next_corrdir):\n",
    "                os.makedirs(next_corrdir)\n",
    "            for p in percentages:\n",
    "                s = int(p*np.shape(mat_corrs)[-1])\n",
    "                slice_corr = mat_corrs[:, :, s-1]\n",
    "                if sliced_corrs.shape[0] == 0:\n",
    "                    sliced_corrs = slice_corr\n",
    "                else:\n",
    "                    sliced_corrs = np.dstack((sliced_corrs, slice_corr))\n",
    "            np.save(os.path.join(next_corrdir, f'{c}.npy'), sliced_corrs)\n",
    "        except:\n",
    "            print('issue loading: ' + con)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For averaged correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# levels = np.arange(0,16,1)\n",
    "# conditions = ['intact', 'paragraph', 'rest', 'word']\n",
    "\n",
    "levels = [12, 13, 14, 15]\n",
    "#conditions = ['intact', 'paragraph', 'word', 'rest']\n",
    "conditions = ['word']\n",
    "\n",
    "for l in levels:\n",
    "    for c in conditions:\n",
    "        con = os.path.join(corrs_dir, f'lev_{l}'+ f'_{c}'+ '.npy')\n",
    "        try:\n",
    "            corrs = np.load(con)\n",
    "            mat_corrs = tc.helpers.vec2mat(corrs)\n",
    "            next_corrdir = os.path.join(data_dir, 'mean_corrs', f'level_{l}')\n",
    "            if not os.path.exists(next_corrdir):\n",
    "                os.makedirs(next_corrdir)\n",
    "            mean_corrs = mat_corrs.mean(axis=2)\n",
    "            np.save(os.path.join(next_corrdir, f'{c}.npy'), mean_corrs)\n",
    "        except:\n",
    "            print('issue loading: ' + con)\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
