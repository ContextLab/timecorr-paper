{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster code to calculate correlations for each order - up to 15th order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import timecorr as tc\n",
    "import math\n",
    "import scipy.spatial.distance as sd\n",
    "from timecorr.helpers import isfc, autofc, mean_combine, corrmean_combine, vec2mat, reduce\n",
    "import mkl\n",
    "mkl.set_num_threads(4)\n",
    "\n",
    "factors = 700\n",
    "if factors == 100:\n",
    "    pieman_name = '../../data/pieman_ica100.mat'\n",
    "else:\n",
    "    pieman_name = '../../data/pieman_data.mat'\n",
    "\n",
    "\n",
    "\n",
    "pieman_data = loadmat(pieman_name)  \n",
    "\n",
    "pieman_conds = ['word']\n",
    "\n",
    "data = []\n",
    "conds = []\n",
    "\n",
    "\n",
    "for c in pieman_conds:\n",
    "    if c == 'paragraph':\n",
    "        if factors == 700:\n",
    "            next_data = list(map(lambda i: pieman_data[c][:, i][0], np.where(np.arange(pieman_data[c].shape[1]) != 3)[0]))\n",
    "        else:\n",
    "            next_data = list(map(lambda i: pieman_data[c][:, i][0], np.where(np.arange(pieman_data[c].shape[1]) != 0)[0]))\n",
    "    else:\n",
    "        next_data = list(map(lambda i: pieman_data[c][:, i][0], np.arange(pieman_data[c].shape[1])))\n",
    "    data.extend(next_data)\n",
    "    conds.extend([c]*len(next_data))\n",
    "\n",
    "\n",
    "all_data = np.array(data)\n",
    "conds = np.array(conds)\n",
    "cfun = isfc\n",
    "rfun = 'eigenvector_centrality'\n",
    "width = 50\n",
    "smooth = 'laplace'\n",
    "raw = 'delta'\n",
    "\n",
    "results_dir = '/dartfs/rc/lab/D/DBIC/CDL/f002s72/timecorr_paper/pieman/results/'\n",
    "\n",
    "#results_dir = '/Users/lucyowen/Desktop/timecorr_env/timecorr_paper/pieman/results/'\n",
    "\n",
    "corrsdir = os.path.join(results_dir, smooth + '_' + str(50) + '_orderedup_corrs')\n",
    "if not os.path.exists(corrsdir):\n",
    "    os.makedirs(corrsdir)\n",
    "    \n",
    "\n",
    "laplace = {'name': 'Laplace', 'weights': tc.laplace_weights, 'params': {'scale': width}}\n",
    "delta = {'name': '$\\delta$', 'weights': tc.eye_weights, 'params': tc.eye_params}\n",
    "gaussian = {'name': 'Gaussian', 'weights': tc.gaussian_weights, 'params': {'var': width}}\n",
    "mexican_hat = {'name': 'Mexican hat', 'weights': tc.mexican_hat_weights, 'params': {'sigma': width}}\n",
    "\n",
    "smooth_parameter = eval(smooth)\n",
    "raw_parameter = eval(raw)\n",
    "\n",
    "smooth_fun=smooth_parameter['weights']\n",
    "smooth_params=smooth_parameter['params']\n",
    "raw_fun=raw_parameter['weights']\n",
    "raw_params=raw_parameter['params']\n",
    "\n",
    "combine = corrmean_combine  \n",
    "\n",
    "levels = range(16)\n",
    "\n",
    "for c in pieman_conds:\n",
    "    for lev in levels:\n",
    "        if os.path.exists(os.path.join(corrsdir, 'd_'+ str(lev) +'_'+ c +'.npy')):\n",
    "            data = np.load(os.path.join(corrsdir, 'd_'+ str(lev) +'_'+ c +'.npy'))\n",
    "            print(str(lev) + '_data loaded')\n",
    "        else:\n",
    "            if lev == 0:\n",
    "                lev_data = all_data[conds == c]\n",
    "            else:\n",
    "                lev_data = data_r\n",
    "            print('lev_data: ' + str(lev_data[0][0]))\n",
    "            data = np.asarray(tc.timecorr([x for x in lev_data], cfun=isfc, rfun=None,\n",
    "                                          weights_function=smooth_fun, weights_params=smooth_params))\n",
    "            print('data: ' + str(data[0][0]))\n",
    "            print(str(lev) + '_smooth data calculated')\n",
    "            corr = tc.helpers.z2r(np.mean(tc.helpers.r2z(np.stack(data, axis=2)), axis=2))\n",
    "            print(str(lev) + '_corrs calculated')\n",
    "            np.save(os.path.join(corrsdir, 'lev_'+ str(lev) +'_'+ c +'.npy'), corr)\n",
    "            data = np.asarray(tc.timecorr([x for x in lev_data], cfun=isfc, rfun=None,\n",
    "                                          weights_function=raw_fun, weights_params=raw_params))\n",
    "            print(str(lev) + '_raw data calculated')\n",
    "            np.save(os.path.join(corrsdir, 'd_'+ str(lev) +'_'+ c +'.npy'), data)\n",
    "        if os.path.exists(os.path.join(corrsdir, 'd_'+ str(lev) +'_r_'+ c +'.npy')):\n",
    "            data_r = np.load(os.path.join(corrsdir, 'd_'+ str(lev) +'_r_'+ c +'.npy'))\n",
    "            print(str(lev) + '_reduced data loaded')\n",
    "        else:\n",
    "            data_r = np.asarray(reduce([x for x in data], rfun=rfun))\n",
    "            print(str(lev) + '_reduced data calculated')\n",
    "            np.save(os.path.join(corrsdir, 'd_'+ str(lev) +'_r_'+ c +'.npy'), data_r)\n",
    "            print('data_r: ' + str(data_r[0][0]))\n",
    "        del data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import timecorr as tc\n",
    "import math\n",
    "import scipy.spatial.distance as sd\n",
    "from timecorr.helpers import isfc, autofc, mean_combine, corrmean_combine, vec2mat, reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/dartfs/rc/lab/D/DBIC/CDL/f002s72/timecorr_paper/pieman/results'\n",
    "corrs_dir = os.path.join(data_dir, 'laplace_50_orderedup_corrs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster code for mean and sliced correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For sliced correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = np.arange(0,16,1)\n",
    "conditions = ['intact', 'paragraph', 'word', 'rest']\n",
    "\n",
    "n = .1\n",
    "percentages = np.arange(n, 1 + n, n)\n",
    "for l in levels:\n",
    "    for c in conditions:\n",
    "        con = os.path.join(corrs_dir, f'lev_{l}'+ f'_{c}' + '.npy')\n",
    "        print(con)\n",
    "        try:\n",
    "            corrs = np.load(con)\n",
    "            mat_corrs = tc.helpers.vec2mat(corrs)\n",
    "            sliced_corrs = np.array([])\n",
    "            next_corrdir = os.path.join(data_dir, 'sliced_corrs', f'level_{l}')\n",
    "            if not os.path.exists(next_corrdir):\n",
    "                os.makedirs(next_corrdir)\n",
    "            for p in percentages:\n",
    "                s = int(p*np.shape(mat_corrs)[-1])\n",
    "                slice_corr = mat_corrs[:, :, s-1]\n",
    "                if sliced_corrs.shape[0] == 0:\n",
    "                    sliced_corrs = slice_corr\n",
    "                else:\n",
    "                    sliced_corrs = np.dstack((sliced_corrs, slice_corr))\n",
    "            np.save(os.path.join(next_corrdir, f'{c}.npy'), sliced_corrs)\n",
    "        except:\n",
    "            print('issue loading: ' + con)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For averaged correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = np.arange(0,16,1)\n",
    "conditions = ['intact', 'paragraph', 'rest', 'word']\n",
    "\n",
    "for l in levels:\n",
    "    for c in conditions:\n",
    "        con = os.path.join(corrs_dir, f'lev_{l}'+ f'_{c}'+ '.npy')\n",
    "        try:\n",
    "            corrs = np.load(con)\n",
    "            mat_corrs = tc.helpers.vec2mat(corrs)\n",
    "            next_corrdir = os.path.join(data_dir, 'mean_corrs', f'level_{l}')\n",
    "            if not os.path.exists(next_corrdir):\n",
    "                os.makedirs(next_corrdir)\n",
    "            mean_corrs = mat_corrs.mean(axis=2)\n",
    "            np.save(os.path.join(next_corrdir, f'{c}.npy'), mean_corrs)\n",
    "        except:\n",
    "            print('issue loading: ' + con)\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
